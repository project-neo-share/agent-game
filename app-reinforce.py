# app.py â€” TU Korea AI Management: Ethical AI Simulation
# ì‘ì„±ì: Prof. Songhee Kang
# Update: Simple E-Greedy RL & Korean Comments

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random
from scipy.stats import pearsonr
from dataclasses import dataclass
from typing import Dict, List

# ==================== 1. ê¸°ë³¸ ì„¤ì • ====================
st.set_page_config(
    page_title="í•œêµ­ê³µí•™ëŒ€ ì¸ê³µì§€ëŠ¥ê²½ì˜: ìœ¤ë¦¬ AI ì—ì´ì „íŠ¸ ê°•í™”í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜", 
    page_icon="ğŸ“", 
    layout="wide"
)

# ==================== 2. ë°ì´í„° ëª¨ë¸ (í™˜ê²½) ====================
@dataclass
class Scenario:
    sid: str
    title: str
    setup: str
    options: Dict[str, str]
    rewards: Dict[str, Dict[str, float]]

# 4ëŒ€ ìœ¤ë¦¬ í”„ë ˆì„ì›Œí¬ ì •ì˜
FRAMEWORKS = ["emotion", "social", "moral", "identity"]

# ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°
DEFAULT_SCENARIOS = [
    Scenario(
        sid="S1", title="1ë‹¨ê³„: ê³ ì „ì  íŠ¸ë¡¤ë¦¬",
        setup="ì„ ë¡œ ìœ„ 5ëª… vs 1ëª…. ë ˆë²„ë¥¼ ë‹¹ê¸¸ ê²ƒì¸ê°€?",
        options={"A": "1ëª… í¬ìƒ (ê°œì…)", "B": "ë°©ê´€ (í˜„ìƒ ìœ ì§€)"},
        rewards={"A": {"emotion": 1.0, "social": -0.5, "moral": -1.0, "identity": 0.5},
                 "B": {"emotion": -1.0, "social": 0.5, "moral": 1.0, "identity": -0.5}}
    ),
    Scenario(
        sid="S2", title="2ë‹¨ê³„: ë§¥ë½ì  ìš”ì†Œ",
        setup="ë¬´ë‹¨ ì¹¨ì…ì 5ëª… vs ê´€ë¦¬ì ìë…€ 1ëª….",
        options={"A": "5ëª… êµ¬ì¡° (ìë…€ í¬ìƒ)", "B": "ê·œì • ì¤€ìˆ˜ (5ëª… ë°©ê´€)"},
        rewards={"A": {"emotion": 0.6, "social": -0.8, "moral": -0.7, "identity": 0.3},
                 "B": {"emotion": -0.5, "social": 0.9, "moral": 0.6, "identity": 0.4}}
    ),
    Scenario(
        sid="S3", title="3ë‹¨ê³„: ì˜ë£Œ ì¬ë‚œ ë¶„ë¥˜",
        setup="ì¼ë°˜ ë¶€ìƒì ë‹¤ìˆ˜ vs ìˆ™ë ¨ëœ ì˜ì‚¬ 1ëª….",
        options={"A": "ì˜ì‚¬ ìš°ì„  (ê³µë¦¬ì£¼ì˜)", "B": "ë™ë“± ëŒ€ìš° (í‰ë“±ì£¼ì˜)"},
        rewards={"A": {"emotion": 0.7, "social": -0.4, "moral": -0.6, "identity": 0.8},
                 "B": {"emotion": -0.3, "social": 0.7, "moral": 0.9, "identity": 0.5}}
    ),
]

# ë¬¸í™”ê¶Œ í”„ë¦¬ì…‹ (Agent ì„±í–¥)
CULTURES_PRESETS = {
    "USA":      {"emotion": 0.3, "social": 0.1, "identity": 0.3, "moral": 0.3},
    "CHINA":    {"emotion": 0.1, "social": 0.5, "identity": 0.2, "moral": 0.2},
    "EUROPE":   {"emotion": 0.3, "social": 0.2, "identity": 0.2, "moral": 0.3},
    "KOREA":    {"emotion": 0.2, "social": 0.2, "identity": 0.4, "moral": 0.2},
    "LATIN_AM": {"emotion": 0.4, "social": 0.2, "identity": 0.2, "moral": 0.2},
    "MIDDLE_E": {"emotion": 0.1, "social": 0.2, "identity": 0.2, "moral": 0.5},
    "AFRICA":   {"emotion": 0.2, "social": 0.4, "identity": 0.2, "moral": 0.2},
}

# ==================== 3. ë‹¨ìˆœ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ (Simple E-Greedy) ====================
class SimpleEGreedyAgent:
    """
    ì•„ì£¼ ê¸°ì´ˆì ì¸ ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    ë³µì¡í•œ Q-Learning(ë¯¸ë˜ ê°€ì¹˜ ê³ ë ¤) ëŒ€ì‹ , í˜„ì¬ í–‰ë™ì˜ í‰ê·  ë³´ìƒê°’ì„ í•™ìŠµí•©ë‹ˆë‹¤.
    """
    def __init__(self, name, weights, scenarios, learning_rate=0.1, epsilon=0.5):
        self.name = name
        self.weights = weights       # ë¬¸í™”ê¶Œ(Agent)ì˜ ê°€ì¹˜ê´€ ê°€ì¤‘ì¹˜
        self.scenarios = scenarios   # í™˜ê²½(Environment) ì •ë³´
        self.lr = learning_rate      # í•™ìŠµë¥  (alpha): ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ë°˜ì˜í• ì§€ (0~1)
        self.epsilon = epsilon       # íƒí—˜ë¥  (epsilon): ëœë¤í•˜ê²Œ í–‰ë™í•  í™•ë¥ 
        
        # ê°€ì¹˜ í…Œì´ë¸” ì´ˆê¸°í™” (Q-Table ì—­í• )
        # ì˜ˆ: {'S1': {'A': 0.0, 'B': 0.0}, ...}
        self.q_table = {s.sid: {"A": 0.0, "B": 0.0} for s in scenarios}
        
    def get_action(self, sid):
        """
        [í–‰ë™ ì„ íƒ: Epsilon-Greedy ì •ì±…]
        ë™ì „ ë˜ì§€ê¸°ì²˜ëŸ¼ epsilon í™•ë¥ ë¡œëŠ” ë¬´ì‘ìœ„ í–‰ë™(íƒí—˜)ì„ í•˜ê³ ,
        ë‚˜ë¨¸ì§€ í™•ë¥ ë¡œëŠ” í˜„ì¬ ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ í–‰ë™(í™œìš©)ì„ ì„ íƒí•©ë‹ˆë‹¤.
        """
        # 1. íƒí—˜ (Exploration): ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì°¾ì•„ ë¬´ì‘ìœ„ ì„ íƒ
        if random.random() < self.epsilon:
            return random.choice(["A", "B"])
        
        # 2. í™œìš© (Exploitation): í˜„ì¬ ì§€ì‹ ì¤‘ ìµœê³ ì˜ ì„ íƒ
        qs = self.q_table[sid]
        if qs["A"] > qs["B"]: return "A"
        elif qs["B"] > qs["A"]: return "B"
        
        # ì ìˆ˜ê°€ ê°™ìœ¼ë©´ ë¬´ì‘ìœ„
        return random.choice(["A", "B"])

    def calculate_reward(self, sid, action):
        """
        [ë³´ìƒ ê³„ì‚°]
        í™˜ê²½(ì‹œë‚˜ë¦¬ì˜¤)ì´ ì£¼ëŠ” ë³´ìƒ ë²¡í„°ì™€ ì—ì´ì „íŠ¸(ë¬¸í™”ê¶Œ)ì˜ ê°€ì¹˜ê´€ì„ ë‚´ì (Dot Product)í•©ë‹ˆë‹¤.
        Reward = Sum(ì‹œë‚˜ë¦¬ì˜¤_ì ìˆ˜ * ë‚´_ê°€ì¤‘ì¹˜) * 10
        """
        scn = next(s for s in self.scenarios if s.sid == sid)
        r_vec = scn.rewards[action]
        
        # 4ê°œ í”„ë ˆì„ì›Œí¬ ì ìˆ˜ í•©ì‚°
        reward = sum(r_vec.get(k, 0) * self.weights.get(k, 0) for k in FRAMEWORKS) * 10
        return reward

    def update(self, sid, action, reward):
        """
        [í•™ìŠµ: ê°€ì¹˜ ì—…ë°ì´íŠ¸]
        ë‹¨ìˆœ ê°±ì‹  ê³µì‹ (Incremental Mean):
        ìƒˆë¡œìš´_ê°€ì¹˜ = ê¸°ì¡´_ê°€ì¹˜ + í•™ìŠµë¥  * (ì‹¤ì œ_ë³´ìƒ - ê¸°ì¡´_ê°€ì¹˜)
        
        * Q-Learningê³¼ ë‹¬ë¦¬ ë¯¸ë˜ ìƒíƒœ(Gamma)ë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        """
        old_val = self.q_table[sid][action]
        
        # ì˜ˆì¸¡ ì˜¤ì°¨(Error) = ì‹¤ì œ ë°›ì€ ë³´ìƒ - ë‚´ê°€ ì˜ˆìƒí•œ ë³´ìƒ
        error = reward - old_val
        
        # ê°€ì¹˜ ì—…ë°ì´íŠ¸
        self.q_table[sid][action] = old_val + self.lr * error

    def decay_epsilon(self):
        """
        [íƒí—˜ë¥  ê°ì†Œ]
        ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ëœë¤ ì„ íƒ(íƒí—˜)ì„ ì¤„ì´ê³ , í•™ìŠµëœ ê²°ê³¼(í™œìš©)ë¥¼ ë” ë¯¿ìŠµë‹ˆë‹¤.
        """
        self.epsilon = max(0.01, self.epsilon * 0.99)

# ==================== 4. ë¶„ì„ ë„êµ¬ ====================
def calculate_diversity(actions_list: List[str]) -> float:
    """í–‰ë™ ë‹¤ì–‘ì„± ì§€í‘œ (0.0: í•œìª½ ì ë¦¼ ~ 1.0: ì™„ë²½í•œ ê· í˜•)"""
    if not actions_list: return 0.0
    a_count = actions_list.count("A")
    ratio = a_count / len(actions_list)
    return 1.0 - (2 * abs(0.5 - ratio))

def run_simulation(culture_name, weights, episodes, custom_scenarios):
    # ë‹¨ìˆœ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    agent = SimpleEGreedyAgent(culture_name, weights, custom_scenarios)
    
    history = {
        "episode": [],
        "reward": [],
        "diversity": []
    }
    
    progress = st.progress(0)
    
    for ep in range(episodes):
        ep_actions = []
        ep_reward = 0
        
        # ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ìˆœíšŒ
        for scn in custom_scenarios:
            # 1. í–‰ë™ ì„ íƒ (E-Greedy)
            action = agent.get_action(scn.sid)
            
            # 2. ë³´ìƒ ê³„ì‚° (ë‚´ì )
            reward = agent.calculate_reward(scn.sid, action)
            
            # 3. í•™ìŠµ (ê°’ ì—…ë°ì´íŠ¸)
            agent.update(scn.sid, action, reward)
            
            ep_actions.append(action)
            ep_reward += reward
        
        # ì—í”¼ì†Œë“œ ì¢…ë£Œ í›„ íƒí—˜ë¥  ê°ì†Œ
        agent.decay_epsilon()
        
        # ê¸°ë¡
        history["episode"].append(ep + 1)
        history["reward"].append(ep_reward)
        history["diversity"].append(calculate_diversity(ep_actions))
        
        if (ep + 1) % 10 == 0:
            progress.progress((ep + 1) / episodes)
            
    progress.empty()
    return pd.DataFrame(history)

# ==================== 5. UI êµ¬ì„± ====================
st.title("ğŸ“ í•œêµ­ê³µí•™ëŒ€ ì¸ê³µì§€ëŠ¥ê²½ì˜: ìœ¤ë¦¬ AI ì—ì´ì „íŠ¸ ê°•í™”í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜")
st.markdown("""
ì´ ì‹œë®¬ë ˆì´í„°ëŠ” **ì´ˆê¸° í˜•íƒœì˜ ê°•í™”í•™ìŠµ**(E-Greedy)ì„ ì‚¬ìš©í•˜ì—¬ AI ì—ì´ì „íŠ¸ê°€ ë¬¸í™”ì  ê°€ì¹˜ê´€ì— ë”°ë¼ ìœ¤ë¦¬ì  ë”œë ˆë§ˆë¥¼ ì–´ë–»ê²Œ í•™ìŠµí•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.
1. **í™˜ê²½ ì„¤ì •**: ê° ì‹œë‚˜ë¦¬ì˜¤ì˜ ì„ íƒì§€ê°€ ì£¼ëŠ” ë³´ìƒì„ ì •ì˜í•©ë‹ˆë‹¤.
2. **ì—ì´ì „íŠ¸ ì„¤ì •**: AIê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” ê°€ì¹˜(ë¬¸í™”ê¶Œ)ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
3. **ê²°ê³¼ ë¶„ì„**: í•™ìŠµ ê³¼ì •ì—ì„œ 'í–‰ë™ì˜ ë‹¤ì–‘ì„±'ê³¼ 'ë³´ìƒ'ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
""")

# --- [ì‚¬ì´ë“œë°”] ì—ì´ì „íŠ¸ ì„¤ì • ---
st.sidebar.header("ğŸ‘¤ 2. ì—ì´ì „íŠ¸(ë¬¸í™”ê¶Œ) ì„¤ì •")
selected_culture = st.sidebar.selectbox("ë¬¸í™”ê¶Œ í”„ë¦¬ì…‹", list(CULTURES_PRESETS.keys()), index=3)
episodes = st.sidebar.slider("í•™ìŠµ íšŸìˆ˜ (Episodes)", 100, 1000, 300, step=50)

st.sidebar.subheader("ê°€ì¹˜ê´€ ê°€ì¤‘ì¹˜ ì¡°ì •")
mod_weights = {}
culture_defaults = CULTURES_PRESETS[selected_culture]

# 4ëŒ€ í”„ë ˆì„ì›Œí¬ ê°€ì¤‘ì¹˜ ì…ë ¥
for k in FRAMEWORKS:
    mod_weights[k] = st.sidebar.slider(f"{k.capitalize()}", 0.0, 1.0, culture_defaults[k])

# ê°€ì¤‘ì¹˜ ì •ê·œí™”
total_w = sum(mod_weights.values()) or 1
final_weights = {k: v/total_w for k, v in mod_weights.items()}

st.sidebar.markdown("---")
st.sidebar.caption("ğŸ“Š ìµœì¢… ì ìš© ê°€ì¤‘ì¹˜")
st.sidebar.json(final_weights)

# --- [ë©”ì¸] í™˜ê²½(ì‹œë‚˜ë¦¬ì˜¤) ì„¤ì • ---
st.header("ğŸŒ 1. í™˜ê²½(ì‹œë‚˜ë¦¬ì˜¤ ë³´ìƒ) ì„¤ì •")
st.info("ê° ì„ íƒì§€ê°€ 4ê°€ì§€ ìœ¤ë¦¬ í”„ë ˆì„ì›Œí¬(Emotion, Social, Moral, Identity)ì—ì„œ ì–´ë–¤ ë³´ìƒ(-1.0 ~ 1.0)ì„ ë°›ëŠ”ì§€ ì„¤ì •í•©ë‹ˆë‹¤.")

custom_scenarios = []
tabs = st.tabs([s.title for s in DEFAULT_SCENARIOS])

for i, (tab, default_scn) in enumerate(zip(tabs, DEFAULT_SCENARIOS)):
    with tab:
        st.markdown(f"> **ìƒí™©:** {default_scn.setup}")
        col_a, col_b = st.columns(2)
        
        # Option A
        with col_a:
            st.markdown(f"### ğŸ…° {default_scn.options['A']}")
            r_a = default_scn.rewards["A"].copy()
            for fw in FRAMEWORKS:
                r_a[fw] = st.slider(f"[A] {fw}", -1.0, 1.0, r_a.get(fw,0.0), 0.1, key=f"s{i}a_{fw}")
        
        # Option B
        with col_b:
            st.markdown(f"### ğŸ…± {default_scn.options['B']}")
            r_b = default_scn.rewards["B"].copy()
            for fw in FRAMEWORKS:
                r_b[fw] = st.slider(f"[B] {fw}", -1.0, 1.0, r_b.get(fw,0.0), 0.1, key=f"s{i}b_{fw}")

        custom_scenarios.append(Scenario(
            default_scn.sid, default_scn.title, default_scn.setup, 
            default_scn.options, {"A": r_a, "B": r_b}
        ))

# --- [ë¶„ì„ ì‹¤í–‰] ---
st.divider()
st.header("ğŸš€ 3. ì‹œë®¬ë ˆì´ì…˜ ë° ë¶„ì„")

if st.button("ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘", type="primary"):
    with st.spinner("AI ì—ì´ì „íŠ¸ê°€ ìœ¤ë¦¬ì  ê°€ì¹˜ë¥¼ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤..."):
        df = run_simulation(selected_culture, final_weights, episodes, custom_scenarios)
    
    st.success("í•™ìŠµ ì™„ë£Œ!")
    
    # 1. í•™ìŠµ ê·¸ë˜í”„
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("ğŸ“ˆ ì´ ë³´ìƒ(Reward) ë³€í™”")
        st.caption("í•™ìŠµì´ ì§„í–‰ë ìˆ˜ë¡ AIê°€ ì–»ëŠ” ë³´ìƒì˜ ì´í•©")
        st.line_chart(df, x="episode", y="reward", color="#FF4B4B")
    with c2:
        st.subheader("ğŸ”€ í–‰ë™ ë‹¤ì–‘ì„±(Diversity) ë³€í™”")
        st.caption("ì„ íƒì˜ ì¹˜ìš°ì¹¨ ì •ë„ (1.0=ê· í˜•, 0.0=í¸í–¥)")
        st.line_chart(df, x="episode", y="diversity", color="#1F77B4")
        
    # 2. ìƒê´€ê´€ê³„ ë¶„ì„
    st.markdown("---")
    st.subheader("ğŸ”— ë‹¤ì–‘ì„±ê³¼ ë³´ìƒì˜ ìƒê´€ê´€ê³„ ë¶„ì„")
    
    r_val, p_val = pearsonr(df["diversity"], df["reward"])
    
    col_plot, col_stat = st.columns([2, 1])
    with col_plot:
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.scatter(df["diversity"], df["reward"], alpha=0.6, c='purple', edgecolors='w')
        
        # ì¶”ì„¸ì„ 
        if len(df) > 1:
            z = np.polyfit(df["diversity"], df["reward"], 1)
            p = np.poly1d(z)
            ax.plot(df["diversity"], p(df["diversity"]), "r--", label="ì¶”ì„¸ì„ ")
            
        ax.set_xlabel("Diversity (0=Bias, 1=Fair/Balance)")
        ax.set_ylabel("Total Reward")
        ax.set_title(f"Correlation Scatter Plot (r={r_val:.2f})")
        ax.grid(True, alpha=0.3)
        ax.legend()
        st.pyplot(fig)
        
    with col_stat:
        st.metric("í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ (r)", f"{r_val:.3f}")
        st.metric("ìœ ì˜í™•ë¥  (P-value)", f"{p_val:.3e}")
        
        st.markdown("#### ğŸ’¡ í•´ì„")
        if r_val > 0.3:
            st.success("âœ… **ì–‘ì˜ ìƒê´€ê´€ê³„**\n\në‹¤ì–‘í•œ ì‹œë„ë¥¼ í• ìˆ˜ë¡ ë” ë†’ì€ ë³´ìƒì„ ì–»ìŠµë‹ˆë‹¤.")
        elif r_val < -0.3:
            st.warning("âš ï¸ **ìŒì˜ ìƒê´€ê´€ê³„**\n\níŠ¹ì • í–‰ë™ì„ ê³ ìˆ˜í•´ì•¼ ë³´ìƒì´ ë†’ìŠµë‹ˆë‹¤.")
        else:
            st.info("âº **ìƒê´€ì—†ìŒ**\n\në‹¤ì–‘ì„±ê³¼ ë³´ìƒì€ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    with st.expander("ğŸ“¥ í•™ìŠµ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"):
        st.dataframe(df.head())
        st.download_button("CSVë¡œ ì €ì¥", df.to_csv(index=False), "ai_ethics_data.csv")
